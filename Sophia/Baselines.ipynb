{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_preprocessed_train = pd.DataFrame(pd.read_csv(os.getcwd() + '/' + 'full_preprocessed_train.csv', sep=','))\n",
    "full_preprocessed_val = pd.DataFrame(pd.read_csv(os.getcwd() + '/' + 'full_preprocessed_dev.csv', sep=','))\n",
    "\n",
    "full_preprocessed_train = full_preprocessed_train.replace(np.nan, \" \")\n",
    "full_preprocessed_val = full_preprocessed_val.replace(np.nan, \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_training_data = full_preprocessed_train['label']\n",
    "y_val_val = full_preprocessed_val['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_train = pd.DataFrame(pd.read_csv(os.getcwd() + '/' + 'lda_train.csv', sep=',', header=None))\n",
    "lda_val = pd.DataFrame(pd.read_csv(os.getcwd() + '/' + 'lda_val.csv', sep=',', header=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250874, 20)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35918, 20)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA without Additional Features (aka just vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA with out additional features\n",
      "Accuracy: 0.898435324906732\n",
      "F1: 0.8503697992239174\n"
     ]
    }
   ],
   "source": [
    "LDA_model = BernoulliNB()\n",
    "LDA_model.fit(lda_train, y_training_data)\n",
    "y_pred = LDA_model.predict(lda_val)\n",
    "print(\"LDA with out additional features\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_val, y_pred))\n",
    "print(\"F1:\", f1_score(y_val_val, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA with Additional Features (aka preprocessed + vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feats = full_preprocessed_train[['user_id', 'prod_id', 'rating',  'length',\n",
    "       'numbers', 'caps', 'num_sent', 'avg_words', 'perc_tot_user_reviews',\n",
    "       'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD',\n",
    "       'NN', 'NNS', 'NNP', 'NNPS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR',\n",
    "       'RBS', 'RP', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT',\n",
    "       'WP', 'WP$', 'WRB']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_num_feats = full_preprocessed_val[['user_id', 'prod_id', 'rating',  'length',\n",
    "       'numbers', 'caps', 'num_sent', 'avg_words', 'perc_tot_user_reviews',\n",
    "       'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD',\n",
    "       'NN', 'NNS', 'NNP', 'NNPS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR',\n",
    "       'RBS', 'RP', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT',\n",
    "       'WP', 'WP$', 'WRB']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA_X_training_data = sparse.hstack((num_feats, lda_train))\n",
    "LDA_X_val_data = sparse.hstack((val_num_feats, lda_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<250874x64 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 9660326 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA_X_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<35918x64 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1382973 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA_X_val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA with additional features\n",
      "Accuracy: 0.8189765577147948\n",
      "F1: 0.8272471328069518\n"
     ]
    }
   ],
   "source": [
    "LDA_model = BernoulliNB()\n",
    "LDA_model.fit(LDA_X_training_data, y_training_data)\n",
    "y_pred = LDA_model.predict(LDA_X_val_data)\n",
    "print(\"LDA with additional features\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_val, y_pred))\n",
    "print(\"F1:\", f1_score(y_val_val, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA just vectorizer and normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = lda_train.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "lda_train_N = pd.DataFrame(x_scaled)\n",
    "\n",
    "x = lda_val.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "lda_val_N = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA with out additional features and Normalized\n",
      "Accuracy: 0.8983239601314105\n",
      "F1: 0.8503142729508569\n"
     ]
    }
   ],
   "source": [
    "LDA_model = BernoulliNB()\n",
    "LDA_model.fit(lda_train_N, y_training_data)\n",
    "y_pred = LDA_model.predict(lda_val_N)\n",
    "print(\"LDA with out additional features and Normalized\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_val, y_pred))\n",
    "print(\"F1:\", f1_score(y_val_val, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_train = pd.DataFrame(pd.read_csv(os.getcwd() + '/' + 'dv_train.csv', sep=',', header=None))\n",
    "doc2vec_val = pd.DataFrame(pd.read_csv(os.getcwd() + '/' + 'dv_val.csv', sep=',', header=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250874, 100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2vec_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35918, 100)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2vec_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec without Additional Features (aka just vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOC2VEC with out additional features\n",
      "Accuracy: 0.8252129851328025\n",
      "F1: 0.8277094500929553\n"
     ]
    }
   ],
   "source": [
    "dv_model = BernoulliNB()\n",
    "dv_model.fit(doc2vec_train, y_training_data)\n",
    "y_pred = dv_model.predict(doc2vec_val)\n",
    "print(\"DOC2VEC with out additional features\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_val, y_pred))\n",
    "print(\"F1:\", f1_score(y_val_val, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec with Additional Features (aka preprocessed + vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOC2VEC_X_training_data = sparse.hstack((num_feats, doc2vec_train))\n",
    "DOC2VEC_X_val_data = sparse.hstack((val_num_feats, doc2vec_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<250874x144 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 29730246 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DOC2VEC_X_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<35918x144 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4256413 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DOC2VEC_X_val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOC2VEC with additional features\n",
      "Accuracy: 0.7603430035079904\n",
      "F1: 0.7938734692738963\n"
     ]
    }
   ],
   "source": [
    "dv_model = BernoulliNB()\n",
    "dv_model.fit(DOC2VEC_X_training_data, y_training_data)\n",
    "y_pred = dv_model.predict(DOC2VEC_X_val_data)\n",
    "print(\"DOC2VEC with additional features\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_val, y_pred))\n",
    "print(\"F1:\", f1_score(y_val_val, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec just vectorizer and normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = doc2vec_train.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "doc2vec_train_N = pd.DataFrame(x_scaled)\n",
    "\n",
    "x = doc2vec_val.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "doc2vec_val_N = pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOC2VEC with out additional features\n",
      "Accuracy: 0.8981290717745977\n",
      "F1: 0.8502170862949754\n"
     ]
    }
   ],
   "source": [
    "dv_model = BernoulliNB()\n",
    "dv_model.fit(doc2vec_train_N , y_training_data)\n",
    "y_pred = dv_model.predict(doc2vec_val_N)\n",
    "print(\"DOC2VEC with out additional features\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_val, y_pred))\n",
    "print(\"F1:\", f1_score(y_val_val, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer \n",
    "\n",
    "#TfidfVectorizer\n",
    "binary_Tfidf_vectorizer = TfidfVectorizer(binary=True, ngram_range=(1, 2))\n",
    "binary_Tfidf_vectorizer.fit(full_preprocessed_train['review'])\n",
    "\n",
    "#stores data in sparse matrix\n",
    "X_train_binary_Tfidf = binary_Tfidf_vectorizer.transform(full_preprocessed_train['review'])\n",
    "X_val_binary_Tfidf = binary_Tfidf_vectorizer.transform(full_preprocessed_val['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<250874x4309860 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 27181974 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_binary_Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<35918x4309860 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3451428 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_binary_Tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF without Additional Features (aka just vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF with out additional features\n",
      "Accuracy: 0.898435324906732\n",
      "F1: 0.8503697992239174\n"
     ]
    }
   ],
   "source": [
    "tfidf_model = BernoulliNB()\n",
    "tfidf_model.fit(X_train_binary_Tfidf, y_training_data)\n",
    "y_pred = tfidf_model.predict(X_val_binary_Tfidf)\n",
    "print(\"TFIDF with out additional features\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_val, y_pred))\n",
    "print(\"F1:\", f1_score(y_val_val, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF with Additional Features (aka preprocessed + vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_X_training_data = sparse.hstack((num_feats, X_train_binary_Tfidf))\n",
    "Tfidf_X_val_data = sparse.hstack((val_num_feats, X_val_binary_Tfidf ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF with additional features\n",
      "Accuracy: 0.898435324906732\n",
      "F1: 0.8503697992239174\n"
     ]
    }
   ],
   "source": [
    "tfidf_model = BernoulliNB()\n",
    "tfidf_model.fit(Tfidf_X_training_data, y_training_data)\n",
    "y_pred = tfidf_model.predict(Tfidf_X_val_data)\n",
    "print(\"TFIDF with additional features\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val_val, y_pred))\n",
    "print(\"F1:\", f1_score(y_val_val, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF just vectorizer and normalized\n",
    "\n",
    "MinMaxScaler does not support sparse input and crashed computer when converted to dense. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imbalanced Classes Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
